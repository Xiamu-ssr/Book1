---
description: Simplified Data Processing on Large Clusters，浅读，标注
---

# MapReduce

{% embed url="https://static.googleusercontent.com/media/research.google.com/zh-CN/archive/mapreduce-osdi04.pdf" %}
MapReduce PDF
{% endembed %}

## 1.Introduction

输入数据通常很大时，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。但是如何并行化计算、分布数据和处理故障等问题，使得原本简单的计算用大量复杂的代码来处理这些问题变得模糊不清。作为对这种复杂性的反应，我们设计了新的抽象，它允许我们表达我们试图执行的简单计算，但隐藏了库中并行化，容错，数据分布和负载平衡的混乱细节。这就是map和reduce。

## 2.Programming Model

MapReduce的基本思想是，用户只需要定义两个函数：map函数和reduce函数。map函数负责对输入数据进行过滤和排序，将数据转换成键值对的形式。reduce函数负责对map函数产生的键值对进行汇总和处理，输出最终结果。

基于MapReduce模型的任务，除了单词统计，还有许多有趣的例子，字符串匹配，URL访问频率，网页链接图，文档关键词统计，倒排索引（文档的单词作为key，文档id作为value，可以快速定位单词的位置。），分布式排序。

## 3.Implementation

MapReduce的工作流程，分为以下几个步骤：

1. 用户程序首先将输入文件切分成M个小块，每个小块的大小通常为16MB到64MB（用户可以通过参数控制）。然后在一个服务器集群中启动多个程序的副本。其中一个副本是特殊的，称为master，负责分配和监控任务。其他的副本是workers，负责执行map或reduce任务。总共有M个map任务和R个reduce任务。
2. master选择空闲的workers，并分配给它们一个map任务或一个reduce任务。一个worker被分配了一个map任务后，就会读取对应的输入文件块的内容，并将其解析成键值对，然后传递给用户定义的map函数。map函数产生的中间键值对会缓存在内存中。
3. 周期性地，缓存中的键值对会被写入到本地磁盘上，并按照一定的规则划分成R个区域。这些键值对在本地磁盘上的位置会被传回给master，master负责将这些位置转发给reduce workers。
4. 当一个reduce worker收到master通知时，它会通过远程调用从map workers的本地磁盘上读取缓存的数据。当一个reduce worker读取完所有的中间数据后，它会对数据按照键进行排序，以便将相同键的值放在一起。排序是必要的，因为通常很多不同的键会映射到同一个reduce任务。如果中间数据太大，无法放在内存中，则需要使用外部排序。
5. reduce worker遍历排序后的中间数据，并对每个唯一的键及其对应的值集合调用用户定义的reduce函数。reduce函数输出的结果会追加到最终输出文件中。
6. 当所有的map任务和reduce任务都完成后，master会唤醒用户程序。此时，MapReduce调用在用户程序中返回。执行成功后，MapReduce产生的输出结果会保存在R个输出文件中（每个reduce任务一个文件，文件名由用户指定）。通常情况下，用户不需要将这些输出文件合并成一个文件——他们可以将这些文件作为另一个MapReduce调用或其他分布式应用程序的输入。

### 3.3Fault Tolerance

Worker Failure：master定期ping每个worker，如果worker没有回应，master将其标记为失效，并回收这个worker负责的任务分配到其它worker上。

Master Failure：如果master fail，可以从上一个检查点状态开始新的副本。然而，考虑到只有一个master，它的失败是不可能的;因此，如果master失败，我们会中止MapReduce计算。

MapReduce计算框架具有容错能力，可以处理不同类型的故障，包括崩溃故障、遗漏故障和任意故障。MapReduce的容错机制主要依赖于map和reduce任务输出的原子提交，以及master和worker之间的心跳检测。

### 3.4Locality

网络带宽是稀缺资源，所以我们使用GFS，输入数据一开始就被分块存在集群磁盘里。

### 3.5Task Granularity

任务粒度指的是将map阶段划分为M个任务，将reduce阶段划分为R个任务的方式。作者指出，理想情况下，M和R应该比worker机器的数量大得多，这样可以提高动态负载均衡和故障恢复的效率。但是，M和R也不能太大，因为master需要做O(M+R)次调度决策，并且在内存中保持O(M\*R)的状态。另外，R通常受到用户的限制，因为每个reduce任务的输出都会保存在一个单独的输出文件中。作者给出了一个实际的例子，他们通常选择M使得每个任务的输入数据大小在16MB到64MB之间（这样可以最大化利用数据局部性优化），并且使R成为worker机器数量的一个小倍数。他们经常使用200000个map任务，5000个reduce任务，和2000台worker机器来进行MapReduce计算。

### 3.6Backup Tasks

备份任务是一种用来缓解拖延者问题的通用机制。拖延者指的是在计算过程中花费异常长时间来完成最后几个map或reduce任务的机器。备份任务的原理是，当一个MapReduce操作接近完成时，master会调度剩余的进行中的任务的备份执行。只要主执行或备份执行有一个完成，任务就被标记为完成。作者指出，这种机制可以显著减少大型MapReduce操作的完成时间，而只增加少量的计算资源消耗。作者给出了一个例子，当禁用备份任务机制时，排序程序的完成时间会增加44%。

## 4.Refinements

虽然简单地编写Map和Reduce函数所提供的基本功能不能满足大多数需求，但我们发现了一些有用的扩展

### 4.1 Partitioning Function

用户可以指定 reduce 任务的数量和输出文件的数量（R），并使用一个分区函数根据中间键对数据进行分区。例如，使用 `hash(Hostname(urlkey )) mod R` 作为分区函数，就可以让同一个主机的所有 URL 都在同一个输出文件中。

### 4.2 Ordering Guarantees

可以保证每台电脑收到的键和值的对是按照键的顺序排列的。

### 4.3 Combiner Function

可以在 map 和 shuffle 之间加入一个合并的步骤，用于把每台电脑处理的结果进行部分合并，减少网络传输的数据量。

### 4.4 Input and Output Types

你可以自己选择你想要怎么读取和写入数据，比如你可以把每行文字当作一个键/值对，也可以把一堆已经排好序的键/值对当作数据。你也可以自己决定怎么把数据分成小块给不同电脑处理，只要保证每块都有意义就行了（比如不能把一行文字切成两半）。你甚至可以从数据库或内存里读取数据，而不是从文件里读取。

### 4.6 Skipping Bad Records

你可能会遇到一些让你程序崩溃或者卡住不动的数据记录。这样会让你整个 MapReduce 都不能完成。如果你不能找到并修复问题所在，或者你觉得少了几条记录也没关系，那么你可以让 MapReduce 自动跳过这些坏记录。

### 4.7 Local Execution

你可能觉得在很多台电脑上运行 MapReduce 很难调试或者测试（比如找不到出错在哪台电脑上）。那么你可以让 MapReduce 在你自己电脑上运行所有步骤（就像只有一台电脑那样），然后你就可以用任何工具来检查或者改进你写出来代码了。

### 4.8 Status Information

主节点有一个网页服务器，可以让你看到你运行 MapReduce 的各方面情况，你可以用这些信息来估计你还要等多久才能完成 MapReduce ，或者你是否需要加更多电脑来帮忙做工作。这些网页也可以让你发现为什么你运行 MapReduce 比你想象中慢得多。另外还能看到哪些电脑出问题了，以及它们出问题时正在做什么任务。这些信息可以帮助你找出你写出来代码里面有什么问题。

### 4.9 Counters

MapReduce 库有一个功能，可以让你数一数你的程序发生了多少次不同的事情。比如，你可以数一数你处理了多少个单词，或者你索引了多少篇德语的文章。你只需要给每种事情起一个名字，然后在你的程序里每次发生的时候就加一。这样，你就可以知道你的程序做了什么，有没有出错，有没有效率。MapReduce 库还会帮你把不同的计算机上的数字加起来，给你一个总的结果。它还会自动去掉重复的数字，避免计算错误。

## 5.Performance

对MapReduce做了性能测试，并且作者故意杀死部分进程，为了检测MapReduce的可靠性和容错性，发现集群仍可以快速恢复并正确完成运算。

## 6.Experience

Google内部关于MapReduce的一些实际经历。

## 8.Conclusions

作者认为 MapReduce 在 Google 得到了成功的应用，有以下几个原因。

第一，这个模型很容易使用，即使是没有并行和分布式系统经验的程序员也可以使用，因为它隐藏了并行化，容错，局部性优化和负载均衡的细节。

第二，很多不同的问题都可以用 MapReduce 来表达和解决。

第三，作者开发了一个 MapReduce 的实现，可以扩展到由数千台机器组成的大型集群。这个实现能够有效地利用这些机器资源，因此适合用于 Google 遇到的许多大规模的计算问题。

{% hint style="info" %}
Q：那么，MapReduce 有没有什么不足之处呢？

A：MapReduce 也有一些不足之处。例如，它不能很好地处理需要多次迭代的计算，因为每次迭代都需要从磁盘读写数据，这会降低性能。它也不能很好地处理需要实时交互的计算，因为它的启动开销和批处理模式会导致延迟。它还不能很好地处理需要复杂的数据流或者依赖关系的计算，因为它的编程模型比较简单和固定。
{% endhint %}
