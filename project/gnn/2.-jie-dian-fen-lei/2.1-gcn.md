# 2.1 GCN

```python
# 导入相关库
import wandb
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn
from torch_geometric.loader import DataLoader
from torch_geometric.datasets import Planetoid
from torch_geometric.nn.models import GCN
from torch_geometric.data import Batch
import numpy as np
```

```python
# 下载数据集
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"device : {device}")

from torch_geometric.datasets import Planetoid
dataset = Planetoid(root='./data/Cora', name='Cora')
graph = dataset[0]
```

```python
# 查看图信息
print(graph)
print(f"train num : {graph.train_mask.sum()}")
print(f"val num : {graph.val_mask.sum()}")
print(f"test num : {graph.test_mask.sum()}")
print(f"num classes : {dataset.num_classes}")
```

```
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
train num : 140
val num : 500
test num : 1000
num classes : 7

x：节点特征矩阵，大小为[num_nodes, num_node_features]，其中num_nodes是图中节点的数量，num_node_features是每个节点的特征维度。例如，对于Cora数据集，x的大小为[2708, 1433]，表示数据集中包含2708个节点，每个节点有1433个特征。
edge_index：边索引矩阵，大小为[2, num_edges]，其中num_edges是图中边的数量。edge_index矩阵用于表示图中的边，其中每列表示一条边的两个端点。例如，对于Cora数据集，edge_index的大小为[2, 10556]，表示数据集中存在10556条边。
y：节点标签向量，大小为[num_nodes]，其中每个元素表示对应节点的类别标签。例如，对于Cora数据集，y的大小为[2708]，表示数据集中每个节点都有一个类别标签，取值范围为0到6。
train_mask：训练集节点的掩码向量，大小为[num_nodes]，其中每个元素为True或False，表示对应节点是否属于训练集。例如，对于Cora数据集，train_mask的大小为[2708]，表示数据集中的所有节点都有一个掩码值，其中True表示该节点属于训练集。
val_mask：验证集节点的掩码向量，大小和train_mask相同，其中每个元素为True或False，表示对应节点是否属于验证集。
test_mask：测试集节点的掩码向量，大小和train_mask相同，其中每个元素为True或False，表示对应节点是否属于测试集。
```

```python
# batch
datalist = [dataset[i].to(device) for i in range(len(dataset))]
data_loader = DataLoader(datalist, batch_size=4, shuffle=True)
```

{% hint style="info" %}
Cora数据集只有一张Graph，而GNN里batch是以Graph为最小单元的，所以这里batch和没batch一样。
{% endhint %}

```python
model = GCN(in_channels=graph.x.shape[1], hidden_channels= 16, num_layers=2, out_channels=dataset.num_classes).to(device)
# print("model type:", type(model))
print(model)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=4e-4)
# print("optimizer type:", type(optimizer))
# criterion = nn.CrossEntropyLoss()
criterion = nn.NLLLoss()
# print("criterion type:", type(criterion))
m = nn.LogSoftmax(dim=1)
# wandb.init(project="GCN")
```

{% hint style="info" %}
这里也可以尝试用CrossEntropyLoss损失函数，不过计算loss时都需要对模型的输出进行soft
{% endhint %}

```python
def train(model:torch_geometric.nn.models.basic_gnn, optimizer:torch.optim, criterion:nn.modules.loss, data_loader:torch_geometric.loader.dataloader, epochs:int):
    for epoch in range(epochs):
        model.train()
        for i, data in enumerate(data_loader):
            optimizer.zero_grad()
            out = model(data.x, data.edge_index)
            loss = criterion(m(out[data.train_mask]), data.y[data.train_mask])
            loss.backward()
            optimizer.step()
        model.eval()
        for i, data in enumerate(data_loader):
            out = model(data.x, data.edge_index)
            loss = criterion(m(out[data.val_mask]), data.y[data.val_mask])
            # wandb.log({"loss":loss.item()})
            _,pred = m(out[data.val_mask]).max(dim=1)
            acc = torch.sum(pred == data.y[data.val_mask]) / len(pred)
            # wandb.log({"acc":acc})
```

```python
def test(model:torch_geometric.nn.models.basic_gnn, optimizer:torch.optim, criterion:nn.modules.loss, data_loader:torch_geometric.loader.dataloader):
    for i, data in enumerate(data_loader):
        out = model(data.x, data.edge_index)
        _, pred = m(out[data.test_mask]).max(dim=1)
        acc = torch.sum(pred == data.y[data.test_mask]) / len(pred)
        print(f"acc:{acc}")
```

```python
train(model=model, optimizer=optimizer, criterion=criterion, data_loader=data_loader, epochs=128)
test(model=model, optimizer=optimizer, criterion=criterion, data_loader=data_loader)
```

acc:0.8050000667572021
